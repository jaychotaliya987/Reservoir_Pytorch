{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.tensor` creates the tensor    \n",
    "`TENSOR.item` returns the python type data from the`torch.tensor`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = torch.tensor(7)\n",
    "\n",
    "vector = torch.tensor([89,69])\n",
    "\n",
    "MATRIX = torch.tensor(\n",
    "    [[12, 21, 12],\n",
    "    [12, 12, 12]]\n",
    ")\n",
    "\n",
    "TENSOR = torch.tensor(\n",
    "    [[[12, 21, 12],\n",
    "    [12, 12, 12],\n",
    "    [23, 4, 334]]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 2, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim, vector.ndim, MATRIX.ndim, TENSOR.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIZE of a tensor - the size of a tensor is such that first number will give us the number of blocks, and following numbers will give us number of sub-blocks and so on, last two numbers will give us the dimension of matrices and 3rd last number will give us the number of matrices in the last sub-block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([]), torch.Size([2]), torch.Size([2, 3]), torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.shape, vector.shape, MATRIX.shape, TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also interestingly there are two functions,   \n",
    "`torch.tensor` which will infer the dtype as is    \n",
    "`torch.Tensor` which is basically `torch.FloatTensor` \n",
    "\n",
    "this is a rabbit of some sort, Tensor is faster then tensor, also I have found out that `torch.Tensor` generates a tensor with that number of random elements.\n",
    "so, `torch.Tensor(7)` will generate a vector with 7 random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7),\n",
       " tensor([-4.4826e+05,  3.1273e-41,  0.0000e+00,  0.0000e+00, -7.1458e-04,\n",
       "          3.1266e-41, -7.5295e-04]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(7), torch.Tensor(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random tensors\n",
    "Creating random tensors is useful in NNets because we can generate a initial weights and biases randomly. and start from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1361, 0.6457, 0.5182],\n",
       "        [0.5545, 0.2711, 0.8037],\n",
       "        [0.1177, 0.9990, 0.0287]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(3, 3)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color image tensors are generally of tensor dim = 3, 3 dimensional tensors, each dimensions representing the activation of different color channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_tensor = torch.rand( size = (224, 224, 3))\n",
    "random_image_tensor.shape, random_image_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeros and Ones\n",
    "zeros and ones tensors for masking and manipulating the tensor via multiplication of summation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = torch.zeros(3, 3) #? 3x3 matrix of zeros\n",
    "ones = torch.ones(3, 3) #? 3x3 matrix of ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Range Tensors and Tansor-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 4, 6, 8])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_tensor = torch.arange(start = 0, end = 10, step = 2) #? 0 to 10 with step 2\n",
    "step_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a zeros tensor but with the shape of a input tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_tensor_like = torch.zeros_like(input=step_tensor) \n",
    "step_tensor_like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Data Types\n",
    "https://pytorch.org/docs/stable/tensors.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default datatype for tensors is float32\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, #* defaults to None, which is torch.float32 or whatever datatype is passed\n",
    "                               device=None, #* defaults to None, which uses the default tensor type\n",
    "                               requires_grad=False) #* if True, operations performed on the tensor are recorded \n",
    "\n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the information about the tensor by `TENSOR.shpae, TENSOR.dtype, TENSOR.device`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the dtype of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16) # torch.half would also work\n",
    "float_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor operations\n",
    "All the basic operations works as you expect the only thing you need to be careful is with some linear algebra operations like dot product, hadamard product and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Multiplication\n",
    "\n",
    "Dot product in linear algebra, no. of rows of the first tensor should match no. column of second tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.21 ms, sys: 162 µs, total: 1.38 ms\n",
      "Wall time: 3.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Matrix multiplication by hand \n",
    "# (avoid doing operations with for loops at all cost, they are computationally expensive)\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "  value += tensor[i] * tensor[i]\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 809 µs, sys: 108 µs, total: 917 µs\n",
      "Wall time: 925 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.matmul` is faster than the for-loop. this is a general guidline in all the library function everywhere. **-DO NOT USE RAW LOOPS-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose function\n",
    "\n",
    "Can be useful when multiplying the same rectangular tensor.    \n",
    "- `torch.transpose (TENSOR, dim0, dim1)` is a way to transpose in a dimension for 2d the obvious transpose is between 0th dim and 1st dim. In 3d or 4d tensor it will transpose the appropriate dims, for example change 3rd with 4th in 5dim tensor.    \n",
    "- `Tensor.T` is a simplified transpose. always transpose last two dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.6094, 0.9322]],\n",
       " \n",
       "         [[0.7446, 0.1235]],\n",
       " \n",
       "         [[0.2225, 0.7060]]]),\n",
       " tensor([[[0.6094],\n",
       "          [0.9322]],\n",
       " \n",
       "         [[0.7446],\n",
       "          [0.1235]],\n",
       " \n",
       "         [[0.2225],\n",
       "          [0.7060]]]),\n",
       " tensor([[[0.6094],\n",
       "          [0.9322]],\n",
       " \n",
       "         [[0.7446],\n",
       "          [0.1235]],\n",
       " \n",
       "         [[0.2225],\n",
       "          [0.7060]]]))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.rand(3, 1, 2)\n",
    "tensor1 = torch.transpose(tensor, 1, 2)\n",
    "tensor, tensor1, tensor.mT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
