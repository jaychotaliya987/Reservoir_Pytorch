{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helper_functions.py already exists, skipping download\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.datasets import load_digits\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from pathlib import Path \n",
    "\n",
    "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
    "if Path(\"helper_functions.py\").is_file():\n",
    "  print(\"helper_functions.py already exists, skipping download\")\n",
    "else:\n",
    "  print(\"Downloading helper_functions.py\")\n",
    "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
    "  with open(\"helper_functions.py\", \"wb\") as f:\n",
    "    f.write(request.content)\n",
    "\n",
    "from helper_functions import plot_predictions, plot_decision_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1     2     3     4     5     6    7    8     9  ...   55   56  \\\n",
       "0   0.0  0.0   5.0  13.0   9.0   1.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1   0.0  0.0   0.0  12.0  13.0   5.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "2   0.0  0.0   0.0   4.0  15.0  12.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "3   0.0  0.0   7.0  15.0  13.0   1.0   0.0  0.0  0.0   8.0  ...  0.0  0.0   \n",
       "4   0.0  0.0   0.0   1.0  11.0   0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "5   0.0  0.0  12.0  10.0   0.0   0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "6   0.0  0.0   0.0  12.0  13.0   0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "7   0.0  0.0   7.0   8.0  13.0  16.0  15.0  1.0  0.0   0.0  ...  0.0  0.0   \n",
       "8   0.0  0.0   9.0  14.0   8.0   1.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "9   0.0  0.0  11.0  12.0   0.0   0.0   0.0  0.0  0.0   2.0  ...  0.0  0.0   \n",
       "10  0.0  0.0   1.0   9.0  15.0  11.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "11  0.0  0.0   0.0   0.0  14.0  13.0   1.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "12  0.0  0.0   5.0  12.0   1.0   0.0   0.0  0.0  0.0   0.0  ...  2.0  0.0   \n",
       "13  0.0  2.0   9.0  15.0  14.0   9.0   3.0  0.0  0.0   4.0  ...  0.0  0.0   \n",
       "14  0.0  0.0   0.0   8.0  15.0   1.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "15  0.0  5.0  12.0  13.0  16.0  16.0   2.0  0.0  0.0  11.0  ...  0.0  0.0   \n",
       "16  0.0  0.0   0.0   8.0  15.0   1.0   0.0  0.0  0.0   0.0  ...  2.0  0.0   \n",
       "17  0.0  0.0   1.0   8.0  15.0  10.0   0.0  0.0  0.0   3.0  ...  0.0  0.0   \n",
       "18  0.0  0.0  10.0   7.0  13.0   9.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "19  0.0  0.0   6.0  14.0   4.0   0.0   0.0  0.0  0.0   0.0  ...  2.0  0.0   \n",
       "\n",
       "     57    58    59    60    61    62   63  target  \n",
       "0   0.0   6.0  13.0  10.0   0.0   0.0  0.0       0  \n",
       "1   0.0   0.0  11.0  16.0  10.0   0.0  0.0       1  \n",
       "2   0.0   0.0   3.0  11.0  16.0   9.0  0.0       2  \n",
       "3   0.0   7.0  13.0  13.0   9.0   0.0  0.0       3  \n",
       "4   0.0   0.0   2.0  16.0   4.0   0.0  0.0       4  \n",
       "5   0.0   9.0  16.0  16.0  10.0   0.0  0.0       5  \n",
       "6   0.0   1.0   9.0  15.0  11.0   3.0  0.0       6  \n",
       "7   0.0  13.0   5.0   0.0   0.0   0.0  0.0       7  \n",
       "8   0.0  11.0  16.0  15.0  11.0   1.0  0.0       8  \n",
       "9   0.0   9.0  12.0  13.0   3.0   0.0  0.0       9  \n",
       "10  0.0   1.0  10.0  13.0   3.0   0.0  0.0       0  \n",
       "11  0.0   0.0   1.0  13.0  16.0   1.0  0.0       1  \n",
       "12  0.0   3.0  11.0   8.0  13.0  12.0  4.0       2  \n",
       "13  2.0  12.0  12.0  13.0  11.0   0.0  0.0       3  \n",
       "14  0.0   0.0  10.0  15.0   4.0   0.0  0.0       4  \n",
       "15  4.0  15.0  16.0   2.0   0.0   0.0  0.0       5  \n",
       "16  0.0   0.0   7.0  15.0  16.0  11.0  0.0       6  \n",
       "17  0.0   0.0  11.0   9.0   0.0   0.0  0.0       7  \n",
       "18  0.0  11.0  14.0   5.0   0.0   0.0  0.0       8  \n",
       "19  0.0   7.0  16.0  16.0  13.0  11.0  1.0       9  \n",
       "\n",
       "[20 rows x 65 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "digits_df = pd.DataFrame(digits.data)\n",
    "digits_df[\"target\"] = digits.target\n",
    "digits_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x75bc69b2bd10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(digits.images[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = torch.tensor(X_train, dtype=torch.float), torch.tensor(X_test, dtype=torch.float), torch.tensor(y_train), torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1437, 64]),\n",
       " torch.Size([360, 64]),\n",
       " torch.Size([1437]),\n",
       " torch.Size([360]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class MNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_features=64, out_features=108)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(in_features=108, out_features=216)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(in_features=216, out_features=10)\n",
    "        self.ReLU = nn.ReLU()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.layer3(self.ReLU(self.layer2(self.ReLU(self.layer1(X)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "    acc = (correct / len(y_pred)) * 100 \n",
    "    return acc\n",
    "\n",
    "def train(model, X_train, X_test, y_train, y_test, epochs= 1000, Learning_rate = 0.01):\n",
    "    torch.manual_seed(42)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr= Learning_rate)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range (epochs):\n",
    "        model.train()\n",
    "\n",
    "        y_logits = model(X_train).squeeze()\n",
    "        y_pred = torch.softmax(y_logits, dim=1)\n",
    "        y_pred_acc = torch.argmax(y_logits, dim = 1)\n",
    "\n",
    "        loss = loss_fn(y_logits, y_train)\n",
    "        acc = accuracy_fn(y_train, y_pred_acc)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "      # 1. Forward pass\n",
    "            test_logits = model(X_test).squeeze()\n",
    "            test_pred = torch.softmax(test_logits, dim=1) # logits -> prediction probabilities -> prediction labels\n",
    "            test_pred_acc = torch.argmax(test_logits, dim=1)\n",
    "      # 2. Calculate loss and accuracy\n",
    "            test_loss = loss_fn(test_logits, y_test)\n",
    "            test_acc = accuracy_fn(y_true=y_test,\n",
    "                             y_pred=test_pred_acc)\n",
    "\n",
    "    # Print out what's happening\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test Loss: {test_loss:.5f}, Test Accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 2.48359, Accuracy: 12.25% | Test Loss: 3.32489, Test Accuracy: 26.39%\n",
      "Epoch: 10 | Loss: 0.26676, Accuracy: 90.68% | Test Loss: 0.22506, Test Accuracy: 91.94%\n",
      "Epoch: 20 | Loss: 0.04061, Accuracy: 99.03% | Test Loss: 0.12055, Test Accuracy: 97.22%\n",
      "Epoch: 30 | Loss: 0.00565, Accuracy: 99.93% | Test Loss: 0.14696, Test Accuracy: 97.22%\n",
      "Epoch: 40 | Loss: 0.00120, Accuracy: 100.00% | Test Loss: 0.14392, Test Accuracy: 98.06%\n",
      "Epoch: 50 | Loss: 0.00044, Accuracy: 100.00% | Test Loss: 0.14280, Test Accuracy: 97.78%\n",
      "Epoch: 60 | Loss: 0.00023, Accuracy: 100.00% | Test Loss: 0.15148, Test Accuracy: 97.78%\n",
      "Epoch: 70 | Loss: 0.00015, Accuracy: 100.00% | Test Loss: 0.15429, Test Accuracy: 97.78%\n",
      "Epoch: 80 | Loss: 0.00011, Accuracy: 100.00% | Test Loss: 0.15493, Test Accuracy: 97.78%\n",
      "Epoch: 90 | Loss: 0.00010, Accuracy: 100.00% | Test Loss: 0.15530, Test Accuracy: 98.06%\n",
      "Epoch: 100 | Loss: 0.00008, Accuracy: 100.00% | Test Loss: 0.15465, Test Accuracy: 98.33%\n",
      "Epoch: 110 | Loss: 0.00007, Accuracy: 100.00% | Test Loss: 0.15423, Test Accuracy: 98.06%\n",
      "Epoch: 120 | Loss: 0.00007, Accuracy: 100.00% | Test Loss: 0.15386, Test Accuracy: 97.78%\n",
      "Epoch: 130 | Loss: 0.00006, Accuracy: 100.00% | Test Loss: 0.15392, Test Accuracy: 98.06%\n",
      "Epoch: 140 | Loss: 0.00006, Accuracy: 100.00% | Test Loss: 0.15409, Test Accuracy: 98.06%\n",
      "Epoch: 150 | Loss: 0.00005, Accuracy: 100.00% | Test Loss: 0.15447, Test Accuracy: 98.06%\n",
      "Epoch: 160 | Loss: 0.00005, Accuracy: 100.00% | Test Loss: 0.15477, Test Accuracy: 98.06%\n",
      "Epoch: 170 | Loss: 0.00004, Accuracy: 100.00% | Test Loss: 0.15517, Test Accuracy: 98.06%\n",
      "Epoch: 180 | Loss: 0.00004, Accuracy: 100.00% | Test Loss: 0.15567, Test Accuracy: 98.33%\n",
      "Epoch: 190 | Loss: 0.00004, Accuracy: 100.00% | Test Loss: 0.15608, Test Accuracy: 98.33%\n"
     ]
    }
   ],
   "source": [
    "Model1 = MNIST()\n",
    "train(Model1, X_train, X_test, y_train, y_test, epochs=200, Learning_rate = 0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
